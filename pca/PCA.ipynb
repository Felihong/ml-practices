{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis, Hauptkomponentenanalyse) ist ein Multivarianten Statistik Verfahren, welches umfangreiche Datensätze strukturiert, vereinfacht und veranschaulicht, indem eine Vielzahl statistischer Variablen durch eine geringere Zahl möglichst aussagekräftiger Linearkombinationen (\"Hauptkomponenten\") genähert wird. (Dimensionen Reduktion)\n",
    "\n",
    "Wir bekommen \"faces\" Datensatz, welches fürs Training der Gesichts Erkennung abgebildet ist. Wir entscheiden uns für eine neue Anzahl an Dimensionenum, und reduzieren die Anzahl von Dimensionen.\n",
    "(http://vis-www.cs.umass.edu/lfw/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst packen wir alle Gesicht Images in einem Ordner ein, lese die nacheinander, gleichzeitig wandeln die (n * n) Array ins (1 * n) Array, damit jede Zeile zu einem Gesichtsbild in der Matrix entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def get_file():\n",
    "    path = 'Ressources/faces'\n",
    "    files = os.listdir(path='Ressources/faces')\n",
    "    s = []\n",
    "    for file in files:\n",
    "        image = np.array(Image.open(path + \"/\" + file))\n",
    "        image = list(np.reshape(image, (1, 4096))[0])\n",
    "        s.append(image)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt fangen wir mit unsere Hauptkomponenten Analyse an, zuerst zentralisieren wir die Dateien, indem jede Demension/Merkmale (entspricht zur Spalte) die durchschnittliche Demension substraiert, damit jede Demension Durchschinitt 0 kriegt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centralized(data):\n",
    "    dataT = np.transpose(data)\n",
    "    for i in range(len(dataT)):\n",
    "        average = np.sum(dataT[i]) / len(dataT[i])\n",
    "        for j in range(len(dataT[i])):\n",
    "            j = j - average\n",
    "    return np.transpose(dataT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und berechnen wir die Kovarianzmatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mycovariance(matrix):\n",
    "    middlevec = get_average(matrix)\n",
    "    length = len(matrix)\n",
    "    matrix1 = np.transpose(np.subtract(matrix, middlevec))\n",
    "    matrix2 = np.transpose(matrix1)\n",
    "    matrix = np.dot(matrix1, matrix2)\n",
    "    return np.divide(matrix, length-1)\n",
    "\n",
    "def get_average(images):\n",
    "    result = np.zeros((len(images[0])), dtype=np.float)\n",
    "    for pixel in range(0, len(images[0])):\n",
    "        sum = 0\n",
    "        for image in range(0, len(images)):\n",
    "            sum += images[image][pixel]\n",
    "        result[pixel] = (sum / len(images))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechne die Eigenwert und Eigenvektor der Kovarianz Matirx von der zentralisierten Datei, und sortieren die\n",
    " Eigenwert, damit wir deren entsprechende k-größte Eigenvektoren bekommen, solche Vektoren sind am meinsten \n",
    " mit einander unabhängig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k(data, k):\n",
    "    value, vector = np.linalg.eig(data)\n",
    "    sorted_indices = np.argsort(value)  # sortierte Index\n",
    "    k_vector = vector[:,sorted_indices[:-k-1:-1]]\n",
    "    return k_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilplizieren die originale Datei(m*n) und die berechnete k-Vektoren(n*k), sodass kriegen wir\n",
    "die reduzierte neue Datei mit (m*k) Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_Kdimension(data, k):\n",
    "    data_central = get_centralized(data)\n",
    "    cov = mycovariance(data_central)\n",
    "    kVec = get_top_k(cov, k)\n",
    "    return np.dot(data, kVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 13233)\n"
     ]
    }
   ],
   "source": [
    "pictures = get_file()\n",
    "new_pic = np.transpose(to_Kdimension(pictures, k=9))\n",
    "\n",
    "print(np.shape(new_pic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt reduzieren wir den Datensatz nur mit Demensionsanzahl 9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
